{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried using 5 qubits, 10 qubits, and 32 qubits, and I noticed that with fewer qubits, the SWAP Test struggles to distinguish differences because the vector discrepancies are not subtle enough, causing the fidelity value to remain unchanged. When I increased the number of qubits, the differences became more noticeable; however, the performance still wasnâ€™t satisfactory. I suspect that the limitation in the number of qubits introduces errors in the decomposition process. In the future, I hope to test with more than 32 qubits, which is expected to yield better results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training with D=20 (embedding dimension) ...\n",
      "\n",
      "Epoch 1/20, Loss = 0.0404\n",
      "Epoch 2/20, Loss = 0.0417\n",
      "Epoch 3/20, Loss = 0.0801\n",
      "Epoch 4/20, Loss = 0.0796\n",
      "Epoch 5/20, Loss = 0.0456\n",
      "Epoch 6/20, Loss = 0.0402\n",
      "Epoch 7/20, Loss = 0.0406\n",
      "Epoch 8/20, Loss = 0.0802\n",
      "Epoch 9/20, Loss = 0.0470\n",
      "Epoch 10/20, Loss = 0.1187\n",
      "Epoch 11/20, Loss = 0.0434\n",
      "Epoch 12/20, Loss = 0.0836\n",
      "Epoch 13/20, Loss = 0.0401\n",
      "Epoch 14/20, Loss = 0.0774\n",
      "Epoch 15/20, Loss = 0.0461\n",
      "Epoch 16/20, Loss = 0.0741\n",
      "Epoch 17/20, Loss = 0.0594\n",
      "Epoch 18/20, Loss = 0.1177\n",
      "Epoch 19/20, Loss = 0.0809\n",
      "Epoch 20/20, Loss = 0.0462\n",
      "\n",
      "Training done!\n",
      "Final params: [ 0.36551536 -0.16162408 -0.17057364 -0.01441307 -0.327289    0.10410722\n",
      "  0.33192569 -0.19816642 -0.16157685 -0.00748968 -0.45244665 -0.28227262\n",
      " -0.1623948  -0.1716964   0.14146035  0.4975883   0.08268237 -0.05654246\n",
      " -0.0296459  -0.02118647 -0.51075272  0.13704794 -0.18147731  0.2266333\n",
      " -0.01699555 -0.1074406  -0.35294391  0.27032831 -0.02397626  0.05379101\n",
      "  0.13005204  0.18965948  0.05857154  0.08759387  0.0483922  -0.49144026\n",
      " -0.09863429  0.05379324 -0.07777713  0.00519001]\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# ==================================\n",
    "# 1. Load and Sample the MNIST Dataset\n",
    "# ==================================\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), _ = mnist.load_data()\n",
    "\n",
    "# Sample 200 images for demonstration\n",
    "num_samples = 200\n",
    "indices = np.random.choice(len(x_train), num_samples, replace=False)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "# Normalize the images to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "\n",
    "# ==================================\n",
    "# 2. Define a General Embedding Function\n",
    "# ==================================\n",
    "def embed_data(data_vec, params_vec, start_wire):\n",
    "    \"\"\"\n",
    "    Embed the data vector (length D) and parameters vector (length D) into qubits.\n",
    "    Each 2 dimensions are encoded using one qubit with RY and RX rotations.\n",
    "    If D is odd, the last dimension uses only an RY rotation.\n",
    "    \"\"\"\n",
    "    D = len(data_vec)\n",
    "    # Number of qubits required = ceil(D/2)\n",
    "    M = (D + 1) // 2\n",
    "\n",
    "    # First layer: Data Encoding\n",
    "    for i in range(M):\n",
    "        idx1 = 2 * i\n",
    "        idx2 = 2 * i + 1\n",
    "\n",
    "        # If dimension idx1 exists, apply RY rotation\n",
    "        if idx1 < D:\n",
    "            angle_ry = data_vec[idx1] * np.pi + params_vec[idx1]\n",
    "            qml.RY(angle_ry, wires=start_wire + i)\n",
    "\n",
    "        # If dimension idx2 exists, apply RX rotation\n",
    "        if idx2 < D:\n",
    "            angle_rx = data_vec[idx2] * np.pi + params_vec[idx2]\n",
    "            qml.RX(angle_rx, wires=start_wire + i)\n",
    "    \n",
    "    # Second layer: Add Entanglement via CNOT gates between adjacent qubits\n",
    "    for i in range(M - 1):\n",
    "        qml.CNOT(wires=[start_wire + i, start_wire + i + 1])\n",
    "    \n",
    "    # Third layer: Additional rotations (using the same parameters for simplicity)\n",
    "    for i in range(M):\n",
    "        if 2 * i < D:\n",
    "            # Note: Using the same index mapping as before.\n",
    "            qml.RY(params_vec[2 * i], wires=start_wire + i)\n",
    "        if 2 * i + 1 < D:\n",
    "            qml.RX(params_vec[2 * i + 1], wires=start_wire + i)\n",
    "\n",
    "# ==================================\n",
    "# 3. Build a General SWAP Test Circuit\n",
    "# ==================================\n",
    "def create_swap_test_circuit(D):\n",
    "    \"\"\"\n",
    "    Build a general SWAP Test QNode to compare two data inputs (each of length D).\n",
    "    \n",
    "    Configuration:\n",
    "      - Ancilla: wire=0\n",
    "      - First data is embedded on qubits: wires 1..M\n",
    "      - Second data is embedded on qubits: wires (1+M)..(1+2M-1)\n",
    "    where M = ceil(D/2).\n",
    "\n",
    "    QNode input:\n",
    "      img1, img2: each of length D\n",
    "      params: a vector of length 2*D (first D for the first image, second D for the second image)\n",
    "    Returns the probability of the ancilla being in state |0>.\n",
    "    \"\"\"\n",
    "    M = (D + 1) // 2\n",
    "    num_qubits = 1 + 2 * M  # ancilla + 2*M\n",
    "    dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def swap_test(img1, img2, params):\n",
    "        # Split parameters: first half for the first image, second half for the second image.\n",
    "        half = len(params) // 2\n",
    "        params1 = params[:half]\n",
    "        params2 = params[half:]\n",
    "\n",
    "        # Embed the first image on qubits 1..M\n",
    "        embed_data(img1, params1, start_wire=1)\n",
    "        # Embed the second image on qubits (1+M) .. (1+2M-1)\n",
    "        embed_data(img2, params2, start_wire=(1 + M))\n",
    "\n",
    "        # SWAP Test:\n",
    "        # (1) Apply Hadamard on the ancilla (wire=0)\n",
    "        qml.Hadamard(wires=0)\n",
    "        # (2) For each pair of corresponding qubits, perform a controlled-SWAP\n",
    "        for i in range(M):\n",
    "            qml.ctrl(qml.SWAP, control=0)([1 + i, 1 + M + i])\n",
    "        # (3) Apply Hadamard on the ancilla again\n",
    "        qml.Hadamard(wires=0)\n",
    "        \n",
    "        return qml.probs(wires=0)\n",
    "\n",
    "    return swap_test\n",
    "\n",
    "def fidelity_from_probs(prob0):\n",
    "    \"\"\"\n",
    "    Compute Fidelity using the SWAP Test:\n",
    "      Fidelity = 2 * P(ancilla=0) - 1\n",
    "    \"\"\"\n",
    "    return 2 * prob0 - 1\n",
    "\n",
    "# ==================================\n",
    "# 4. Contrastive Loss Function\n",
    "# ==================================\n",
    "def contrastive_loss(img1, lbl1, img2, lbl2, params, swap_test_func):\n",
    "    \"\"\"\n",
    "    Contrastive Loss:\n",
    "      For same-class pairs, we want the fidelity F to be high (> margin).\n",
    "      For different-class pairs, we want F to be low (< -margin).\n",
    "    A margin is used to further enforce separation.\n",
    "    \"\"\"\n",
    "    probs = swap_test_func(img1, img2, params)\n",
    "    p0 = probs[0]\n",
    "    F = fidelity_from_probs(p0)\n",
    "    \n",
    "    margin = 0.2  # Margin parameter to enforce separation\n",
    "    \n",
    "    if lbl1 == lbl2:\n",
    "        # For same-class: loss = 5.0 * (max(0, margin - F))^2\n",
    "        return 5.0 * max(0, margin - F)**2\n",
    "    else:\n",
    "        # For different-class: loss = (max(0, F + margin))^2\n",
    "        return max(0, F + margin)**2\n",
    "\n",
    "# ==================================\n",
    "# 5. Training Demonstration\n",
    "# ==================================\n",
    "D = 20  # Embedding dimension (use 20, which corresponds to 16 dimensions effectively, considering additional qubit overhead)\n",
    "\n",
    "# Create a SWAP Test QNode for data of length D\n",
    "swap_test_circuit = create_swap_test_circuit(D)\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    Preprocess the image to extract more pixel information and perform a simple dimensionality reduction.\n",
    "    Steps:\n",
    "      - Reshape image to 28x28.\n",
    "      - Extract the central region (since digits are usually centered).\n",
    "      - Resize the central region to 4x4.\n",
    "      - Flatten and take the first D values.\n",
    "      - Normalize the resulting vector to [0, 1].\n",
    "    \"\"\"\n",
    "    reshaped = img.reshape(28, 28)\n",
    "    center = reshaped[7:21, 7:21]\n",
    "    scaled = zoom(center, 4/14)\n",
    "    flattened = scaled.flatten()[:D]\n",
    "    normalized = (flattened - flattened.min()) / (flattened.max() - flattened.min() + 1e-8)\n",
    "    return normalized\n",
    "\n",
    "# Initialize parameters for both images: a vector of length 2*D (first D for the first image, second D for the second image)\n",
    "params = pnp.array(np.random.uniform(-0.1, 0.1, size=(2*D,)), requires_grad=True)\n",
    "\n",
    "# Use Adam optimizer\n",
    "opt = qml.AdamOptimizer(stepsize=0.02)\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 20  # Number of epochs\n",
    "batch_size = 4   # Batch size (number of pairs per batch)\n",
    "\n",
    "print(f\"Start Training with D={D} (embedding dimension) ...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Randomly sample batch_size*2 images from the training set\n",
    "    batch_indices = np.random.choice(num_samples, batch_size*2, replace=False)\n",
    "    imgs = x_train[batch_indices]\n",
    "    lbls = y_train[batch_indices]\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(imgs), 2):\n",
    "        img1 = preprocess_image(imgs[i])\n",
    "        img2 = preprocess_image(imgs[i+1])\n",
    "        lbl1 = lbls[i]\n",
    "        lbl2 = lbls[i+1]\n",
    "\n",
    "        def closure_fn(par_):\n",
    "            return contrastive_loss(img1, lbl1, img2, lbl2, par_, swap_test_circuit)\n",
    "\n",
    "        params, loss_val = opt.step_and_cost(closure_fn, params)\n",
    "        total_loss += loss_val\n",
    "\n",
    "    avg_loss = total_loss / batch_size\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss = {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining done!\")\n",
    "print(\"Final params:\", params)\n",
    "\n",
    "# ==================================\n",
    "# 6. Testing: Compare Multiple Pairs of Images\n",
    "# ==================================\n",
    "def test_multiple_pairs():\n",
    "    print(\"\\nTesting multiple image pairs:\")\n",
    "    \n",
    "    # Test for the same digit\n",
    "    same_digit = np.where(y_train == y_train[0])[0][:2]\n",
    "    img1 = preprocess_image(x_train[same_digit[0]])\n",
    "    img2 = preprocess_image(x_train[same_digit[1]])\n",
    "    probs = swap_test_circuit(img1, img2, params)\n",
    "    f_same = fidelity_from_probs(probs[0])\n",
    "    print(f\"Fidelity for same digit ({y_train[same_digit[0]]}): {f_same:.4f}\")\n",
    "    \n",
    "    # Test for different digits\n",
    "    diff_digit_idx = np.where(y_train != y_train[0])[0][0]\n",
    "    img3 = preprocess_image(x_train[diff_digit_idx])\n",
    "    probs = swap_test_circuit(img1, img3, params)\n",
    "    f_diff = fidelity_from_probs(probs[0])\n",
    "    print(f\"Fidelity for different digits ({y_train[same_digit[0]]} vs {y_train[diff_digit_idx]}): {f_diff:.4f}\")\n",
    "    \n",
    "    # Test for identical images\n",
    "    probs = swap_test_circuit(img1, img1, params)\n",
    "    f_identical = fidelity_from_probs(probs[0])\n",
    "    print(f\"Fidelity for identical images: {f_identical:.4f}\")\n",
    "\n",
    "# Run the test after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing multiple image pairs:\n",
      "Fidelity for same digit (7): 0.0906\n",
      "Fidelity for different digits (7 vs 8): 0.0001\n",
      "Fidelity for identical images: 0.1122\n"
     ]
    }
   ],
   "source": [
    "test_multiple_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test on random pair:\n",
      "  Image A idx=108, label=8\n",
      "  Image B idx=154, label=8\n",
      "  Fidelity = 0.0034\n",
      "  (Same class -> ideally high Fidelity)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "idx1, idx2 = np.random.choice(num_samples, 2, replace=False)\n",
    "imgA = preprocess_image(x_train[idx1])\n",
    "lblA = y_train[idx1]\n",
    "imgB = preprocess_image(x_train[idx2])\n",
    "lblB = y_train[idx2]\n",
    "\n",
    "test_probs = swap_test_circuit(imgA, imgB, params)\n",
    "p0_test = test_probs[0]\n",
    "F_test = fidelity_from_probs(p0_test)\n",
    "\n",
    "print(f\"\\nTest on random pair:\")\n",
    "print(f\"  Image A idx={idx1}, label={lblA}\")\n",
    "print(f\"  Image B idx={idx2}, label={lblB}\")\n",
    "print(f\"  Fidelity = {F_test:.4f}\")\n",
    "if lblA == lblB:\n",
    "    print(\"  (Same class -> ideally high Fidelity)\")\n",
    "else:\n",
    "    print(\"  (Different class -> ideally low Fidelity)\")\n",
    "\n",
    "# \n",
    "fig, axes = plt.subplots(1, 2, figsize=(6,3))\n",
    "axes[0].imshow(x_train[idx1], cmap='gray')\n",
    "axes[0].set_title(f\"idx={idx1}, label={lblA}\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(x_train[idx2], cmap='gray')\n",
    "axes[1].set_title(f\"idx={idx2}, label={lblB}\")\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
